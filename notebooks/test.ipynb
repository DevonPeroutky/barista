{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b39f4de-8146-467d-a18b-bc66256fad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "from transformers import BlipProcessor, Blip2Processor, Blip2ForConditionalGeneration, BlipForConditionalGeneration\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec170426-1b95-4812-b259-efa330a6c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '../datasets/full_ds.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40acb431-a565-44ff-9e4e-c4d8bc179c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the header to the file only if file doesn't exist already\n",
    "if not os.path.exists(output_file):\n",
    "    with open(f'output_file', 'w+') as out_file:\n",
    "        out_file.write(f'submission_id,comment_id,comment,width,height,image_url,image_path\\n')\n",
    "\n",
    "with open(input_file, 'r', newline='') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    for row in reader:\n",
    "        columns = row\n",
    "        comment = ','.join(columns[2:-4])\n",
    "            \n",
    "        if 'on my last attempt at Tinder' in comment:\n",
    "            print(row)\n",
    "            # comment = comment.replace('\"', '\"\"')\n",
    "            # print(comment)\n",
    "            \n",
    "            \n",
    "        # wrapped_comment = f'\"{comment}\"'\n",
    "        new_columns = columns[:2] + [comment] + columns[-4:]\n",
    "        writer.writerow(new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef6105f-a807-4fbf-ab8c-8a29e9fe0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd4fed-b2dd-4cd5-980c-7d66626adb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "block_size = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948e238-b35d-4ebf-a359-4c13a65a57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the DataFrame using iterrows\n",
    "for index, row in df.iterrows():\n",
    "    comments = row['comments']\n",
    "\n",
    "    print(f\"Row {index}: Column1={column1_value}, Column2={column2_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198c3160-b0cb-4a41-96d7-4f9e41a29d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummy targets (float values)\n",
    "targets_data = [random.random() for i in range(10)]\n",
    "\n",
    "# creating DataFrame from targets_data\n",
    "targets_df = pd.DataFrame(data=targets_data)\n",
    "targets_df.columns = ['targets']\n",
    "\n",
    "# creating tensor from targets_df \n",
    "torch_tensor = torch.tensor(targets_df['targets'].values)\n",
    "\n",
    "# printing out result\n",
    "print(torch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e944011-e4d8-44d7-9731-ee961a7d6c97",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1754709515.py, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 31\u001b[0;36m\u001b[0m\n\u001b[0;31m    rows =\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "data = [\"Sometimes the line between life and suicide is as thin as your hair.   Stay strong dude. \\n\"]\n",
    "\n",
    "def build_batch(rows):\n",
    "    xb = [] # B,T\n",
    "    yb = [] # B,1 \n",
    "\n",
    "    for row in rows:\n",
    "        context = []\n",
    "        \n",
    "        # tokenize the row\n",
    "        tokenized = processor.tokenizer.encode(text=row)\n",
    "        print(row)\n",
    "        print(tokenized)\n",
    "        \n",
    "        # for token\n",
    "        for idx, t in enumerate(tokenized):\n",
    "            if idx == 0:\n",
    "                continue\n",
    "                \n",
    "            context = tokenized[0:idx]\n",
    "            label = tokenized[idx:idx + 1]\n",
    "\n",
    "            xb.append(context)\n",
    "            yb.append(label)\n",
    "            \n",
    "    return xb, yb\n",
    "\n",
    "# Iterate through the DataFrame using iterrows\n",
    "def get_batch(batch_size: int = 1):\n",
    "    indexes = [random.randint(0, len(df)) for _ in range(batch_size)]\n",
    "\n",
    "\n",
    "get_batch(5)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    comment = row['comment']\n",
    "    xb, yb = build_batch(comment)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737c2b4-7d65-4d5e-8043-ad023e4efd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/full_ds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e60d9c-7001-43ba-a0a1-8a7a83917ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['comment'].apply(lambda str: processor.tokenizer.encode(str))\n",
    "df['encoded_ids'] = df['comment'].astype(str).apply(processor.tokenizer.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94554d6a-f9d0-4025-af98-cf91a494fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_series = df['encoded_ids']\n",
    "tensor_data = torch.tensor(column_series.values, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32125d6d-b79c-47dd-9016-d1ced1691ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor(list(df['encoded_ids'][0].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a7293-46cf-4754-88d1-615f4a4c5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.tokenizer.encode(\"Sup\", return_tensors='pt', padding=\"max_length\",max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44157fa7-1496-4ff8-9b53-13038504f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment'].astype(str).apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9fcbd4-89f8-47d4-b7cd-fde052a0d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_inputs = df['comment'].astype(str).apply(lambda str: str[:500]).apply(lambda str: processor.tokenizer.encode(str, padding=\"max_length\",max_length=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33997204-1d45-43bf-b1ea-f0f5d1bc364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(tokenized_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a1d63-fa7b-4268-acf1-f96452492b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ce0d65-4dc1-4a4d-9b1f-53df9541c4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
